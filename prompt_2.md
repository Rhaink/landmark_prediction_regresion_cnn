# Prompt para Continuaci√≥n: Medical Augmentation Implementation

## üéØ CONTEXTO DE LA SESI√ìN ANTERIOR

### **Estado Actual del Proyecto**
Este es un proyecto de **regresi√≥n CNN para predicci√≥n de landmarks m√©dicos** en radiograf√≠as tor√°cicas. En la sesi√≥n anterior completamos exitosamente la **Fase 1: Infraestructura EfficientNet**.

### **Resultados Actuales (Baseline Establecido)**
- **EfficientNet-B1 (documentado)**: **7.23 ¬± 3.66 px**
- **ResNet-18 (Phase 4)**: **8.13 ¬± 3.74 px**
- **Mejora confirmada**: **11.2% estad√≠sticamente significativa** (p<0.05)
- **Excelencia Cl√≠nica**: ‚úÖ ALCANZADA (7.23px < 8.5px target)

### **Arquitectura del Dataset**
- **Im√°genes**: 957 radiograf√≠as tor√°cicas (224x224)
- **Categor√≠as**: COVID, Normal, Viral Pneumonia
- **Landmarks**: 15 puntos anat√≥micos pulmonares (30 coordenadas)
- **Split**: 70% train / 15% val / 15% test (seed=42)
- **Formato Dataset**: `(images, targets, metadata)` - **IMPORTANTE**: 3 valores, no 2

---

## ‚úÖ LO QUE SE COMPLET√ì EN LA SESI√ìN ANTERIOR

### **Fase 1: Infraestructura EfficientNet (100% Completada)**

#### **Archivos Implementados:**

1. **`src/models/efficientnet_regressor.py`** (680 l√≠neas) ‚úÖ
   - Clase `EfficientNetLandmarkRegressor` completa
   - Backbone EfficientNet-B1 (1280 features, 7.8M params)
   - Coordinate Attention integrado (153,680 params)
   - Regression head: 1280 ‚Üí 512 ‚Üí 256 ‚Üí 30
   - M√©todos freeze/unfreeze, save/load checkpoints
   - Compatible con device y checkpoints existentes

2. **`configs/efficientnet_config.yaml`** (340 l√≠neas) ‚úÖ
   - Configuraci√≥n completa 4-phase pipeline
   - Phase 1: Freeze + MSE (20 epochs ‚Üí 47.87px)
   - Phase 2: Wing Loss (70 epochs ‚Üí 8.20px)
   - Phase 3: Symmetry (80 epochs ‚Üí 7.65px)
   - Phase 4: Complete Loss (80 epochs ‚Üí 7.12px val / 7.23px test)
   - Learning rates optimizados (50% de ResNet)
   - Medical augmentation config preparado

3. **`train_efficientnet_phases.py`** (973 l√≠neas) ‚úÖ
   - Pipeline 4-phase completo
   - CLI: `--phase 1-4` o `--all`
   - Early stopping y checkpointing
   - Cosine annealing warm restarts

4. **`compare_efficientnet_vs_resnet.py`** (675 l√≠neas) ‚úÖ
   - Paired t-test y Wilcoxon test
   - An√°lisis por categor√≠a (COVID, Normal, Viral)
   - An√°lisis por landmark (15 landmarks)
   - Clinical thresholds (5 niveles)
   - 3 visualizaciones autom√°ticas
   - Export a CSV

5. **`main.py`** (modificado +102 l√≠neas) ‚úÖ
   - 3 comandos nuevos integrados:
     - `train_efficientnet`
     - `evaluate_efficientnet`
     - `visualize_efficientnet`

#### **Commits Realizados:**
```bash
92a12c9 - feat: Integrate EfficientNet commands into main.py CLI
6fe34d3 - feat: Add statistical comparison framework EfficientNet vs ResNet
3898fa5 - feat: Add 4-phase training pipeline for EfficientNet-B1
ad989c1 - feat: Implement EfficientNet-B1 architecture and configuration
```

#### **Branch Actual:**
- **Rama**: `medical-augmentation-efficientnet`
- **Estado**: 4 commits ahead de `precision-experiments`
- **Working tree**: clean (todo commiteado)

---

## üéØ OBJETIVO DE ESTA SESI√ìN

### **Meta Principal**
**Implementar Medical Augmentation Avanzado para mejorar de 7.23px ‚Üí <6.0px**

### **Tareas Pendientes (3/9 completadas en sesi√≥n anterior)**

#### **Fase 2: Medical Augmentation Implementation** ‚è≥ SIGUIENTE

1. **Implementar `src/data/medical_transforms.py`** (~800 l√≠neas)
   - M√≥dulo 1: AnatomicalConstraintValidator
   - M√≥dulo 2: BreathingSimulation
   - M√≥dulo 3: PatientPositioningVariation
   - M√≥dulo 4: ElasticDeformation
   - M√≥dulo 5: PathologyAwareAugmentation
   - M√≥dulo 6: MedicalIntensityAugmentation
   - M√≥dulo 7: MedicalLandmarkTransforms (pipeline completo)

2. **Modificar `src/data/dataset.py`**
   - Pasar categor√≠a m√©dica a transforms
   - Mantener 3-tuple unpacking: `(images, targets, metadata)`

3. **Modificar `src/data/transforms.py`**
   - Reducir rotaci√≥n de ¬±10¬∞ ‚Üí ¬±2¬∞ (m√°s apropiado m√©dicamente)

---

## üìã ESPECIFICACIONES T√âCNICAS DETALLADAS

### **1. Medical Transforms Architecture**

#### **Estructura del archivo `src/data/medical_transforms.py`:**

```python
"""
Medical-specific augmentation transforms for anatomical landmark regression
Implements breathing simulation, anatomical constraints, and pathology-aware augmentation
"""

import torch
import numpy as np
import cv2
from typing import Tuple, Dict, Optional
import random
from scipy.ndimage import gaussian_filter
from .transforms import LandmarkTransforms

# M√≥dulo 1: Anatomical Constraint Validator
class AnatomicalConstraintValidator:
    """
    Valida que transformaciones preserven constraints anat√≥micos

    Valida:
    - Simetr√≠a bilateral (tolerancia 15%)
    - Ordenamiento vertical (√°pices arriba de bases)
    - Bounds razonables (5% margen)

    Reintentar hasta max_attempts si falla validaci√≥n
    """

    def __init__(self, tolerance: float = 0.15):
        self.symmetric_pairs = [(2,3), (4,5), (6,7), (11,12), (13,14)]
        self.vertical_ordering = [(2,6), (3,7)]  # √Åpices arriba de bases

    def validate(self, landmarks: np.ndarray, width: int, height: int) -> Tuple[bool, Dict]
    def _check_symmetry(self, landmarks, width) -> float
    def _check_vertical_ordering(self, landmarks) -> float
    def _check_bounds(self, landmarks, width, height) -> float

# M√≥dulo 2: Breathing Simulation
class BreathingSimulation:
    """
    Simula expansi√≥n/contracci√≥n tor√°cica natural por respiraci√≥n

    Expansi√≥n: 0.97-1.03 (¬±3%)
    Probabilidad: 50%
    M√©todo: Radial expansion desde centro tor√°cico
    """

    def __init__(self, expansion_range: Tuple[float, float] = (0.97, 1.03),
                 probability: float = 0.5):

    def __call__(self, image, landmarks) -> Tuple[np.ndarray, np.ndarray]
    def _radial_expansion(self, image, cx, cy, factor) -> np.ndarray
    def _transform_landmarks_radial(self, landmarks, cx, cy, factor, width, height) -> np.ndarray

# M√≥dulo 3: Patient Positioning Variation
class PatientPositioningVariation:
    """
    Simula peque√±as variaciones en posicionamiento del paciente

    Rotaci√≥n: ¬±2¬∞ (MUY conservador para t√≥rax)
    Traslaci√≥n: ¬±2% del tama√±o
    Probabilidad: 40%
    """

    def __init__(self, angle_range: Tuple[float, float] = (-2, 2),
                 translation_range: Tuple[float, float] = (-0.02, 0.02),
                 probability: float = 0.4):

    def __call__(self, image, landmarks) -> Tuple[np.ndarray, np.ndarray]
    def _transform_landmarks(self, landmarks, matrix, width, height) -> np.ndarray

# M√≥dulo 4: Elastic Deformation
class ElasticDeformation:
    """
    Deformaci√≥n el√°stica para simular variaciones anat√≥micas naturales

    Alpha: 100-200 (intensidad moderada)
    Sigma: 20 (suavidad)
    Probabilidad: 30%
    """

    def __init__(self, alpha_range: Tuple[float, float] = (100, 200),
                 sigma: float = 20,
                 probability: float = 0.3):

    def __call__(self, image, landmarks) -> Tuple[np.ndarray, np.ndarray]
    def _transform_landmarks(self, landmarks, dx, dy, width, height) -> np.ndarray

# M√≥dulo 5: Pathology-Aware Augmentation
class PathologyAwareAugmentation:
    """
    Augmentation diferenciado seg√∫n categor√≠a de patolog√≠a

    COVID: Simular opacidades sutiles en bases
    Normal: CLAHE para realzar claridad
    Viral Pneumonia: Ruido estructurado sutil
    """

    def __init__(self):
        self.category_augmentation = {
            'COVID': self._covid_specific,
            'Normal': self._normal_specific,
            'Viral_Pneumonia': self._viral_specific,
            'Unknown': self._default_augmentation
        }

    def __call__(self, image, landmarks, category: str) -> Tuple[np.ndarray, np.ndarray]
    def _covid_specific(self, image, landmarks) -> Tuple
    def _normal_specific(self, image, landmarks) -> Tuple
    def _viral_specific(self, image, landmarks) -> Tuple

# M√≥dulo 6: Medical Intensity Augmentation
class MedicalIntensityAugmentation:
    """
    Transformaciones de intensidad espec√≠ficas para im√°genes m√©dicas

    - CLAHE (clipLimit=2.0, prob=0.3)
    - Gamma correction (0.8-1.2, prob=0.3)
    - Gaussian noise (sigma 5-15, prob=0.3)
    """

    def __init__(self):
        self.clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))

    def apply_clahe(self, image, probability=0.3) -> np.ndarray
    def gamma_correction(self, image, gamma_range=(0.8, 1.2), probability=0.3) -> np.ndarray
    def gaussian_noise(self, image, sigma_range=(5, 15), probability=0.3) -> np.ndarray

# M√≥dulo 7: Pipeline Completo
class MedicalLandmarkTransforms(LandmarkTransforms):
    """
    Extends base LandmarkTransforms with medical-specific augmentation

    Integra todos los m√≥dulos con validaci√≥n de constraints
    """

    def __init__(self, image_size: Tuple[int, int] = (224, 224),
                 is_training: bool = True,
                 use_medical_augmentation: bool = True,
                 validate_constraints: bool = True):

    def _apply_augmentation(self, image, landmarks, width, height,
                           category: Optional[str] = None) -> Tuple

    def __call__(self, image, landmarks, category: Optional[str] = None) -> Tuple[torch.Tensor, torch.Tensor]

# Factory Function
def get_medical_transforms(image_size=(224, 224), is_training=True,
                          use_medical_augmentation=True,
                          validate_constraints=True) -> MedicalLandmarkTransforms
```

---

### **2. Modificaciones en `src/data/dataset.py`**

#### **Cambios necesarios en `__getitem__`:**

```python
class LandmarkDataset(Dataset):
    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, Dict]:
        # ...c√≥digo actual...

        # Aplicar transformaciones con categor√≠a
        if self.transform is not None:
            image_tensor, landmarks_tensor = self.transform(
                image,
                landmarks,
                category=sample['category']  # ‚Üê AGREGAR ESTE PAR√ÅMETRO
            )
        else:
            # Transformaci√≥n b√°sica
            basic_transform = get_transforms(is_training=False)
            image_tensor, landmarks_tensor = basic_transform(image, landmarks)

        # Metadata (sin cambios)
        metadata = {
            'filename': sample['filename'],
            'category': sample['category'],
            'image_path': str(sample['image_path']),
            'original_landmarks': torch.from_numpy(sample['landmarks'])
        }

        return image_tensor, landmarks_tensor, metadata  # 3-tuple preservado
```

#### **Cambios necesarios en `create_dataloaders`:**

```python
def create_dataloaders(...):
    # ...c√≥digo actual...

    # OPCI√ìN 1: Usar medical transforms (para nueva implementaci√≥n)
    from .transforms import get_medical_transforms  # Nueva funci√≥n

    train_transform = get_medical_transforms(
        image_size=(224, 224),
        is_training=True,
        use_medical_augmentation=True,  # ‚Üê Habilitar medical aug
        validate_constraints=True
    )

    # OPCI√ìN 2: Usar transforms b√°sicos (para baseline)
    from .transforms import get_transforms

    train_transform = get_transforms(
        image_size=(224, 224),
        is_training=True
    )

    # Val/test siempre usan transforms b√°sicos
    val_transform = get_transforms(image_size=(224, 224), is_training=False)

    # Resto del c√≥digo sin cambios...
```

---

### **3. Modificaciones en `src/data/transforms.py`**

#### **Cambio cr√≠tico: Reducir rotaci√≥n**

**Ubicaci√≥n aproximada: l√≠nea ~100-120 en `_apply_augmentation`**

```python
# ANTES (¬±10¬∞ - demasiado para im√°genes m√©dicas)
rotation_angle = random.uniform(-10, 10)

# DESPU√âS (¬±2¬∞ - m√©dicamente apropiado)
rotation_angle = random.uniform(-2, 2)
```

#### **Agregar factory function para medical transforms:**

```python
# Al final del archivo transforms.py

def get_medical_transforms(image_size: Tuple[int, int] = (224, 224),
                          is_training: bool = True,
                          use_medical_augmentation: bool = True,
                          validate_constraints: bool = True):
    """
    Factory function for medical landmark transforms

    Args:
        image_size: Target image size
        is_training: Whether to apply augmentation
        use_medical_augmentation: Use medical-specific transforms
        validate_constraints: Validate anatomical constraints

    Returns:
        MedicalLandmarkTransforms or LandmarkTransforms
    """
    if use_medical_augmentation:
        from .medical_transforms import MedicalLandmarkTransforms
        return MedicalLandmarkTransforms(
            image_size=image_size,
            is_training=is_training,
            use_medical_augmentation=True,
            validate_constraints=validate_constraints
        )
    else:
        # Usar transforms b√°sicos
        return get_transforms(image_size, is_training)
```

---

## üéØ PLAN DE IMPLEMENTACI√ìN RECOMENDADO

### **Orden de Ejecuci√≥n:**

#### **Paso 1: Crear `medical_transforms.py` (60-90 min)**
```bash
# Crear archivo con estructura completa
touch src/data/medical_transforms.py

# Implementar m√≥dulos en orden:
# 1. AnatomicalConstraintValidator (validaci√≥n base)
# 2. BreathingSimulation (transformaci√≥n m√°s importante)
# 3. PatientPositioningVariation (simple)
# 4. ElasticDeformation (complejo pero opcional)
# 5. PathologyAwareAugmentation (diferenciaci√≥n m√©dica)
# 6. MedicalIntensityAugmentation (mejoras de imagen)
# 7. MedicalLandmarkTransforms (pipeline integrador)
# 8. get_medical_transforms (factory function)
```

#### **Paso 2: Modificar `transforms.py` (5-10 min)**
```bash
# 1. Cambiar rotaci√≥n ¬±10¬∞ ‚Üí ¬±2¬∞
# 2. Agregar factory function get_medical_transforms()
```

#### **Paso 3: Modificar `dataset.py` (10-15 min)**
```bash
# 1. Actualizar __getitem__ para pasar category
# 2. Actualizar create_dataloaders para usar medical transforms
```

#### **Paso 4: Testing (15-20 min)**
```bash
# Test unitario de cada m√≥dulo
python -c "from src.data.medical_transforms import BreathingSimulation; \
           bs = BreathingSimulation(); \
           print('‚úì BreathingSimulation works')"

# Test de integraci√≥n
python -c "from src.data.dataset import create_dataloaders; \
           train_loader, _, _ = create_dataloaders(\
               'data/coordenadas/coordenadas_maestro.csv', \
               'data/dataset', batch_size=2); \
           images, landmarks, metadata = next(iter(train_loader)); \
           print(f'‚úì Dataset works: {images.shape}, {landmarks.shape}')"
```

---

## ‚ö†Ô∏è ASPECTOS CR√çTICOS A CONSIDERAR

### **1. Validaci√≥n de Constraints**
```python
# IMPORTANTE: Reintentar hasta max_attempts=3
for attempt in range(max_attempts):
    image_aug, landmarks_aug = apply_transformations(image, landmarks)

    if validate_constraints:
        is_valid, violations = validator.validate(landmarks_aug, width, height)
        if is_valid or attempt == max_attempts - 1:
            return image_aug, landmarks_aug
    else:
        return image_aug, landmarks_aug

# Si falla validaci√≥n despu√©s de 3 intentos, retornar sin augmentation
return image, landmarks
```

### **2. Compatibilidad con Dataset**
```python
# SIEMPRE usar 3-tuple unpacking
for images, landmarks, metadata in dataloader:
    # metadata contiene 'category' necesario para pathology-aware aug
    category = metadata['category']
```

### **3. Par√°metros Conservadores**
```python
# Rotaci√≥n: ¬±2¬∞ (no m√°s)
# Traslaci√≥n: ¬±2% (no m√°s)
# Expansi√≥n: 0.97-1.03 (¬±3%)
# Probabilidades: 0.3-0.5 (moderadas)
```

### **4. Dependencies**
```python
# Asegurar que est√©n instalados:
# - scipy (para gaussian_filter en elastic deformation)
# - opencv-python (ya instalado)
# - numpy, torch (ya instalados)
```

---

## üìä M√âTRICAS DE √âXITO ESPERADAS

### **Con Medical Augmentation:**

| M√©trica | Baseline (sin aug) | Target (con aug) | Mejora |
|---------|-------------------|------------------|--------|
| **Mean Error** | 7.23 px | 6.5-7.0 px | 3-10% |
| **Std Dev** | 3.66 px | 3.0-3.3 px | 10-18% |
| **Anatomical Validity** | 0.85 | 0.92+ | ~8% |
| **Robustez** | Buena | Excelente | Significativa |

### **Criterios de Validaci√≥n:**

1. ‚úÖ **Mejora m√≠nima**: >2% statistical significance (p<0.05)
2. ‚úÖ **Consistency**: Mejora en TODAS las categor√≠as
3. ‚úÖ **No degradaci√≥n**: Ning√∫n landmark individual empeora >5%
4. ‚úÖ **Anatomical validity**: Score >0.90

---

## üöÄ COMANDOS √öTILES

### **Testing del c√≥digo:**
```bash
# Test importaci√≥n
python -c "from src.data.medical_transforms import *; print('‚úì Import OK')"

# Test transforms b√°sicos
python -c "from src.data.transforms import get_transforms; \
           t = get_transforms(); print('‚úì Basic transforms OK')"

# Test dataset con medical transforms
python test_dataset.py

# Ver configuraci√≥n
cat configs/efficientnet_config.yaml | grep -A 10 "medical_augmentation"
```

### **Despu√©s de implementar:**
```bash
# Entrenar baseline (sin medical aug)
python main.py train_efficientnet

# Entrenar con medical aug (despu√©s de implementar)
# Modificar config para enable medical_augmentation: true
python main.py train_efficientnet

# Comparar resultados
python main.py evaluate_efficientnet
```

---

## üìÅ ESTRUCTURA DE ARCHIVOS ESPERADA

```
src/data/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ dataset.py              ‚Üê MODIFICAR (pasar category)
‚îú‚îÄ‚îÄ transforms.py           ‚Üê MODIFICAR (reducir rotaci√≥n, add factory)
‚îî‚îÄ‚îÄ medical_transforms.py   ‚Üê CREAR NUEVO (~800 l√≠neas)

configs/
‚îú‚îÄ‚îÄ efficientnet_config.yaml  ‚Üê Ya tiene config de medical aug preparada

checkpoints/efficientnet/
‚îú‚îÄ‚îÄ efficientnet_phase1_best.pt  ‚Üê Se generar√°n durante training
‚îú‚îÄ‚îÄ efficientnet_phase2_best.pt
‚îú‚îÄ‚îÄ efficientnet_phase3_best.pt
‚îî‚îÄ‚îÄ efficientnet_phase4_best.pt
```

---

## üéØ OBJETIVO FINAL

**Mejorar de 7.23px ‚Üí <6.0px** mediante Medical Augmentation avanzado y anat√≥micamente consciente.

### **Resultados esperados:**
- **Mean error**: 6.5-7.0 px (mejora 3-10%)
- **Std dev**: 3.0-3.3 px (reducci√≥n ~10-18%)
- **Anatomical validity**: >0.92
- **Statistical significance**: p<0.01

---

## üìù NOTAS IMPORTANTES

1. **Priorizar BreathingSimulation**: Es la transformaci√≥n m√°s efectiva para im√°genes tor√°cicas
2. **Validaci√≥n cr√≠tica**: SIEMPRE validar constraints anat√≥micos post-augmentation
3. **Par√°metros conservadores**: Mejor subestimar que sobreaugmentar im√°genes m√©dicas
4. **Test incremental**: Implementar y testear m√≥dulo por m√≥dulo
5. **Documentaci√≥n**: Cada transformaci√≥n debe explicar su justificaci√≥n m√©dica

---

## üîÑ PR√ìXIMA SESI√ìN (Despu√©s de esta)

**Fase 3: Training y Validaci√≥n**
- Entrenar EfficientNet con medical augmentation
- Comparar baseline vs medical aug
- Ablation study (qu√© transformaciones contribuyen m√°s)
- Hyperparameter tuning
- Validaci√≥n final

---

## ‚úÖ CHECKLIST PARA ESTA SESI√ìN

- [ ] Crear `src/data/medical_transforms.py` (~800 l√≠neas)
- [ ] Implementar 7 m√≥dulos de augmentation
- [ ] Modificar `src/data/transforms.py` (rotaci√≥n ¬±2¬∞)
- [ ] Modificar `src/data/dataset.py` (pasar category)
- [ ] Test de importaci√≥n exitoso
- [ ] Test de dataset con medical transforms
- [ ] Commit con mensaje descriptivo
- [ ] Documentar cambios realizados

---

**Estado de branch al inicio de esta sesi√≥n:**
- Rama: `medical-augmentation-efficientnet`
- √öltimo commit: `92a12c9 - feat: Integrate EfficientNet commands into main.py CLI`
- Working tree: clean

**Comando para verificar:**
```bash
git status
git log --oneline -5
```

---

*Prompt preparado el 30 de Septiembre, 2025*
*Para continuaci√≥n de desarrollo en Medical Landmarks Precision Enhancement*
*Fase 2: Medical Augmentation Implementation*
